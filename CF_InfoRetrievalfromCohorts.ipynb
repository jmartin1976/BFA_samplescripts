{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4Ly3Vh0GmjGM1kvAZfqGy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmartin1976/BFA_samplescripts/blob/main/CF_InfoRetrievalfromCohorts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions to retrieve content and structure it from company candidates to Catalist Fund"
      ],
      "metadata": {
        "id": "W3MyY_LkxKnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next steps\n",
        "* Store JSON information in CSVs\n",
        "* Retrieve for each founder\n",
        "  gender\n",
        "  first time founder\n",
        "  university"
      ],
      "metadata": {
        "id": "NV7ZErMHkxzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!sudo apt-get update\n",
        "!sudo apt-get -qq install poppler-utils tesseract-ocr\n",
        "# Upgrade Pillow to latest version\n",
        "%pip install -q --user --upgrade pillow\n",
        "# Install Python Packages\n",
        "%pip install -q unstructured[\"local-inference\"]==0.8.4\n",
        "!pip install kora"
      ],
      "metadata": {
        "id": "JikKawSrdyU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157e6a18-9c0c-4a75-a3ab-060e9529dd80"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.257)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.19)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [849 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [834 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 2,020 kB in 2s (1,114 kB/s)\n",
            "Reading package lists... Done\n",
            "Requirement already satisfied: kora in /usr/local/lib/python3.10/dist-packages (0.9.20)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from kora) (7.34.0)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from kora) (1.5.29)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastcore->kora) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastcore->kora) (23.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.19.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->kora) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->kora) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->kora) (0.2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3vtZLezeAKf",
        "outputId": "e593c2b9-5e88-441a-f9e9-b557d5a135cc"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import requests\n",
        "from requests.exceptions import InvalidURL\n",
        "\n",
        "import io\n",
        "from io import BytesIO\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "#import re\n",
        "import openai\n",
        "\n",
        "#from transformers import GPT2Tokenizer\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from googleapiclient.http import MediaIoBaseUpload\n",
        "\n",
        "from kora.xattr import get_id"
      ],
      "metadata": {
        "id": "yz43A291xJoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee58ccc-90f1-4517-e153-cb5e404be13d"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your Bing Search V7 subscription key to your environment variables.\n",
        "# SUBSCRIPTION_KEY = os.environ['BING_SEARCH_V7_SUBSCRIPTION_KEY']\n",
        "# ENDPOINT = os.environ['BING_SEARCH_V7_ENDPOINT']\n",
        "bing_subscription_key = \"cb9f53c0a43e42c99eb31985e0e67baf\"\n",
        "bing_search_url = \"https://api.bing.microsoft.com\"+\"/v7.0/search\"\n",
        "#search_term = \"Nneile Nkholise where did she studied?\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "cS7SJPnj_vOu"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_domain_fromName(name,domain):\n",
        "  name_parts = name.split()\n",
        "  name_slug = ''.join(name_parts).lower()\n",
        "  print(name_slug)\n",
        "  # Compare the two strings\n",
        "  if name_slug == domain:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def is_domain_fromEmail(email,domain):\n",
        "  if ('@' not in email) or (not email):\n",
        "  # Handle the case where the email string does not contain a '@' character\n",
        "    return 0\n",
        "  email_domain = email.split('@')[1].split('.')[0]\n",
        "  # Compare the two strings\n",
        "  if email_domain == domain:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "oY8z6DCXFsdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_URL_fromNameEmail(name,email,context,bing_subscription_key,bing_search_url):\n",
        "  headers = {\"Ocp-Apim-Subscription-Key\": bing_subscription_key}\n",
        "  query=name+context\n",
        "  params = {\"q\": query,\n",
        "          \"textDecorations\": True,\n",
        "          \"textFormat\": \"HTML\",\n",
        "          \"count\": 3}\n",
        "  response = requests.get(bing_search_url, headers=headers, params=params)\n",
        "  response.raise_for_status()\n",
        "  search_results = response.json()\n",
        "\n",
        "  # Print the search results\n",
        "  for result in search_results[\"webPages\"][\"value\"]:\n",
        "    parsed_url = urlparse(result[\"url\"])\n",
        "    domain_parts = parsed_url.netloc.split('.')\n",
        "    second_level_domain = domain_parts[-2]\n",
        "    # print(result[\"url\"])\n",
        "    if is_domain_fromName(name,second_level_domain):\n",
        "      # print(f\"{second_level_domain} matches {name}\")\n",
        "      return result[\"url\"]\n",
        "    else:\n",
        "      if is_domain_fromEmail(email,second_level_domain):\n",
        "        # print(f\"{second_level_domain} matches {email}\")\n",
        "        return result[\"url\"]\n",
        "  return(\"no url found\")"
      ],
      "metadata": {
        "id": "3jWuG8Tm_CpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_URL_fromNameEmail(\"TechFusion Africa\",\"matt@techfsn.com\",\"\",bing_subscription_key,bing_search_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xar0IyXrAbOt",
        "outputId": "4a99b9fb-c89f-41ef-ccad-736587a8dc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "techfusionafrica\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.techfsn.com/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# opens filepath, look for companyname row and retrieve candidate urls from bing based on Company Name and basic string comparison\n",
        "# stores the url_candidate in a new row URL_candidate\n",
        "def get_URL_candidates(filepath,sheetname,content):\n",
        "  auth.authenticate_user()\n",
        "  creds, _ = default()\n",
        "  # uses credentials of the user running the script\n",
        "  gc = gspread.authorize(creds)\n",
        "  sh = gc.open_by_url(filepath)\n",
        "  worksheet = sh.worksheet(sheetname)\n",
        "  # get_all_values gives a list of rows.\n",
        "  rows = worksheet.get_all_values()\n",
        "  df=pd.DataFrame.from_records(rows,columns=worksheet.row_values(1))\n",
        "  # get column names\n",
        "  column_names = df.columns.tolist()\n",
        "  # drop column names from the dataframe\n",
        "  df = df.drop(df.index[0])\n",
        "  urls = []\n",
        "  #for _,row in df.iloc[158:163].iterrows():\n",
        "  for _,row in df.iterrows():\n",
        "    # Obtain URL from document using bing\n",
        "    companyname=row[\"Startup Name\"]\n",
        "    email=row[\"Email\"]\n",
        "    url=\"\"\n",
        "    url=get_URL_fromNameEmail(companyname,email,\"\",bing_subscription_key,bing_search_url)\n",
        "    # print and add URL to the list\n",
        "    # print(f\"For {companyname} the url bing provided is : {url}\")\n",
        "    # Append the URL to the Google Sheet\n",
        "    urls.append(url)\n",
        "  #creates a column candidate url in the dataframe\n",
        "  df['candidate url'] = urls\n",
        "  # updates google sheet with new values in the dataframe\n",
        "  values = df.values.tolist()\n",
        "  # crean content in the google sheet\n",
        "  worksheet.clear()\n",
        "  # updates google sheets with new values\n",
        "  worksheet.update(values)\n",
        "  column_names = df.columns.tolist()\n",
        "  #inset back column names\n",
        "  worksheet.insert_row(column_names, 1)\n",
        "  return rows"
      ],
      "metadata": {
        "id": "6fq6jJifwu4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_URL_content(url):\n",
        "  # create an id\n",
        "  # store the content in id_webcontent.txt\n",
        "  # get the url\n",
        "  # save id in id column\n",
        "  # save a link to id_webcontent in column url_content\n",
        "  try:\n",
        "    if \"://\" not in url or url.count('/') < 3:\n",
        "      print(f\"Invalid URL: {url}\")\n",
        "      return None\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    return soup.get_text()\n",
        "  except InvalidURL as e:\n",
        "    print(f\"An error occurred while processing the URL {url}: {e}\")\n",
        "    return None\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred while processing the URL {url}: {e}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "46axGQvdXiyg"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_URL_content(\"https://cleantechnologyhub.com/\"))"
      ],
      "metadata": {
        "id": "mCUSJVBrYBV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath='https://docs.google.com/spreadsheets/d/1n4cB9QQwWvAVXlz9XEXFJ1Skv7Jabl32I1qHvennZus/edit#gid=567602188'\n",
        "sheetname=\"K12 Pipeline\""
      ],
      "metadata": {
        "id": "JaPWOda9y3k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PDF2txt(folderpath):\n",
        "  auth.authenticate_user()\n",
        "  creds, _ = default()\n",
        "  service = build('drive', 'v3', credentials=creds)\n",
        "  #read from a folder all the pdfs, names should include an identifier to relate to the company\n",
        "  pdf_files = [f for f in os.listdir(pdf_folder_path) if (f.endswith('.pdf')or(f.endswith('.pptx'))]\n",
        "  for pdf_file in pdf_files:\n",
        "    print(pdf_file)\n",
        "    file_path = os.path.join(folderpath, pdf_file)\n",
        "    loader = UnstructuredFileLoader(file_path)\n",
        "    docs = loader.load()\n",
        "    content=docs[0].page_content[:]\n",
        "    #get the folderid and creates the txt in the same folder, remove the extension pdf\n",
        "    folder_id = get_id(folderpath)\n",
        "    file_metadata = {'name': f\"{pdf_file}.txt\", \"parents\": [folder_id],'mimeType': 'text/plain'}\n",
        "    media = MediaIoBaseUpload(BytesIO(content.encode()), mimetype='text/plain')\n",
        "    # Create the file in Google Drive\n",
        "    file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "    print(f'File ID: {file.get(\"id\")}')"
      ],
      "metadata": {
        "id": "RecF6NkpwuCu"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW-sc_UnKc9Z"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "pdf_folder_path = f'{root_dir}/CF_PDF/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(PDF2txt(pdf_folder_path))"
      ],
      "metadata": {
        "id": "RUZdycidw_Ts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd62322-a022-4d91-886e-a5a0f13c1f68"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tolbi - Pitch Deck.pdf\n",
            "File ID: 1oVKNQkUSahR0-fvvJaFMJNEtTM5BPhKQ\n",
            "Bio-Logical_20230516.pdf\n",
            "File ID: 1aC0S7zLy-_uYtx6wBlAQnDoqvXomkoTo\n",
            "Thola_20230523.pdf\n",
            "File ID: 1gB4F6YFpW297taFvFY4BskXHTyhi0pAG\n",
            "NoorNation_202305_Pitch deck.pdf\n",
            "File ID: 1me1OvPYAti83lp7ke5ZJo-OmOtuo9JZG\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_GPT_on_txtfile(folderpath,query,format):\n",
        "  #how to remove this from here\n",
        "  openai.api_key=os.environ[\"OPENAI_API_KEY\"]\n",
        "  auth.authenticate_user()\n",
        "  creds, _ = default()\n",
        "  service = build('drive', 'v3', credentials=creds)\n",
        "  #read from a folder all the pdfs, names should include an identifier to relate to the company\n",
        "  txt_files=\"\"\n",
        "  txt_files = [f for f in os.listdir(pdf_folder_path) if f.endswith('.txt')]\n",
        "  for txt_file in txt_files:\n",
        "    print(txt_file)\n",
        "    file_path = os.path.join(folderpath, txt_file)\n",
        "    loader = UnstructuredFileLoader(file_path)\n",
        "    docs = loader.load()\n",
        "    content=docs[0].page_content[:]\n",
        "    try:\n",
        "      # Code to make API request goes here\n",
        "      response = openai.ChatCompletion.create(\n",
        "        #model=\"gpt-3.5-turbo\",\n",
        "        #use 16k version in order to allow processing the docs\n",
        "        model='gpt-3.5-turbo-16k',\n",
        "        messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "          {\"role\": \"user\", \"content\": f\"{content}\\n\\n{query}\\n\\n{format}\"},\n",
        "        ]\n",
        "      )\n",
        "      print(response['choices'][0]['message']['content'])\n",
        "    except Exception as e:  # Catch all exceptions\n",
        "      error_message = str(e)\n",
        "      if \"maximum context length\" in error_message:\n",
        "        print(\"The request is too long for the model:\", e)\n",
        "      else:\n",
        "        print(\"An error ocurred with openAI:\", e)\n"
      ],
      "metadata": {
        "id": "MPaYg4wD93ki"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query='''Please extract the following information:\n",
        "user_type: what users are they serving\n",
        "technology: which technology they use\n",
        "problem: the problem that the startup is working on\n",
        "stage: Stage of the company or current fundraise (pre-see, seed, seriesA)\n",
        "founder name. Include up to 3 founder names\n",
        "If the information is not available in the dec, write NA'''\n",
        "format='''generate a JSON-formatted string in this format\n",
        "{\\\"user_type\\\": \\\"value\\\",\n",
        "\\\"technology\\\": \\\"value\\\",\n",
        "\\\"problem\\\": \\\"value\\\",\n",
        "\\\"stage\\\": \\\"value\\\",\n",
        "\\\"founder1\\\": \\\"value\\\",\n",
        "\\\"founder2\\\": \\\"value\\\",\n",
        "\\\"founder3\\\": \\\"value\\\"}'''\n",
        "print(ask_GPT_on_txtfile(pdf_folder_path,query,format))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdeeFUTJXoR0",
        "outputId": "cc2d89aa-b4f7-4607-9530-58ce85c2cacd"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tolbi - Pitch Deck.pdf.txt\n",
            "{\"user_type\": \"Small scale producers, Agri businesses, Local communities\",\n",
            "\"technology\": \"Cloud-based AI decision-making platform using satellite images\",\n",
            "\"problem\": \"Lack of data leading to increased production costs, low income for farmers, water waste and low yield, fertilizer waste, post-harvest losses\",\n",
            "\"stage\": \"Seed\",\n",
            "\"founder1\": \"Mouhamadou L. KEBE\",\n",
            "\"founder2\": \"Daouda SECK\",\n",
            "\"founder3\": \"Cherif Younouss NDIAYE\"}\n",
            "Bio-Logical_20230516.pdf.txt\n",
            "{\"user_type\": \"Climate-vulnerable communities in Africa\",\n",
            "\"technology\": \"Nature-based carbon removals and biochar production\",\n",
            "\"problem\": \"Climate change impacts on African smallholders, including temperature rise, droughts, and soil degradation\",\n",
            "\"stage\": \"Seed\",\n",
            "\"founder1\": \"Philip Hunter\",\n",
            "\"founder2\": \"Rory Buckworth\",\n",
            "\"founder3\": \"NA\"}\n",
            "NoorNation_202305_Pitch deck.pdf.txt\n",
            "{\"user_type\": \"Small & Medium Farming & Touristic Businesses\",\n",
            "\"technology\": \"Decentralized green infrastructure\",\n",
            "\"problem\": \"Lack of access to safely-managed water and clean energy in less-served communities\",\n",
            "\"stage\": \"Seed\",\n",
            "\"founder1\": \"Eman Wahby\",\n",
            "\"founder2\": \"Zeinab AbolElNasr\",\n",
            "\"founder3\": \"Ragy Ramadan\"}\n",
            "Thola_20230523.pdf.txt\n",
            "{\n",
            "\"user_type\": \"Farmers and enterprise buyers in the agricultural export market\",\n",
            "\"technology\": \"Compliance automation for the agricultural supply chain\",\n",
            "\"problem\": \"Shortage of certification bodies for export compliance certification in Africa\",\n",
            "\"stage\": \"Pre-seed\",\n",
            "\"founder1\": \"Nneile Nkholise\",\n",
            "\"founder2\": \"Dancan Angwenyi\",\n",
            "\"founder3\": \"Alan Pohl\"\n",
            "}\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dwtJ-TqoXyXJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}